{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of Subjective Assignment - 9 - Pandas 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G0BZHRgzZrZ",
        "colab_type": "text"
      },
      "source": [
        "# Assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQBOuK0HztYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6c2760be-86a5-46ae-efdf-fe7905f74bdd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dptdb24hzZrb",
        "colab_type": "text"
      },
      "source": [
        "Link for Datasets\n",
        "(https://drive.google.com/drive/folders/105ftuIwN9kqyPNEEm3E6IM7LqywjyvJa?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99hoCPGHzZrc",
        "colab_type": "text"
      },
      "source": [
        "Q21. Write a pandas program to import three datasheets from a given\n",
        "excel data (coalpublic2013.xlsx ) in to a single dataframe.\n",
        " \n",
        "Note: Structure of three datasheets are same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD64WA5_zZre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "6eab9ca0-5735-4fcf-8622-0c0f596c259a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df1 = pd.read_excel('/content/drive/My Drive/Copy of coalpublic2013.xlsx')\n",
        "df2 = pd.read_excel('/content/drive/My Drive/Copy of coalpublic2013.xlsx')\n",
        "df3 = pd.read_excel('/content/drive/My Drive/Copy of coalpublic2013.xlsx')\n",
        "df = pd.concat([df1, df2, df3])\n",
        "print(df)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Year  MSHA ID                       Mine_Name  Production  Labor_Hours\n",
            "0   2013   103381            Tacoa Highwall Miner       56004        22392\n",
            "1   2013   103404                Reid School Mine       28807        28447\n",
            "2   2013   100759  North River #1 Underground Min     1440115       474784\n",
            "3   2013   103246                      Bear Creek       87587        29193\n",
            "4   2013   103451                     Knight Mine      147499        46393\n",
            "..   ...      ...                             ...         ...          ...\n",
            "45  2013  1519322                         Ghm #25       25054         3108\n",
            "46  2013   103321                  Poplar Springs      189370        76366\n",
            "47  2013   103358                       Old Union      284563       161805\n",
            "48  2013  5000030                        Usibelli     1631584       286079\n",
            "49  2013   201195                    Kayenta Mine     7602722      1015333\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si-tLkQ8zZrk",
        "colab_type": "text"
      },
      "source": [
        "Q 22. Write a pandas program to import three datasheets from a given\n",
        "excel data (employee.xlsx ) into a single data frame and export the\n",
        "result into new Excel file.\n",
        " \n",
        "Note: Structure of three datasheets are same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGQYu8DPzZrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df1 = pd.read_excel('/content/drive/My Drive/Copy of coalpublic2013.xlsx')\n",
        "df2 = pd.read_excel('/content/drive/My Drive/Copy of coalpublic2013.xlsx')\n",
        "df3 = pd.read_excel('/content/drive/My Drive/Copy of coalpublic2013.xlsx')\n",
        "df = pd.concat([df1, df2, df3])\n",
        "df.to_excel('output.xlsx', index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47QQVksPzZrq",
        "colab_type": "text"
      },
      "source": [
        "Q23. Write a pandas program to create the Pivot table with multiple\n",
        "indexes from the data set of the titanic.csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9Ez0bedzZrr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "0d693990-e655-45c1-ce84-328dd4ca942c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('/content/drive/My Drive/Copy of titanic.csv')\n",
        "result = pd.pivot_table(df, index = [\"sex\",\"age\"], aggfunc=np.sum)\n",
        "print(result)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Unnamed: 15  adult_male  alone  ...  pclass  sibsp  survived\n",
            "sex    age                                    ...                         \n",
            "female 0.75           0.0         0.0    0.0  ...       6      4         2\n",
            "       1.00           0.0         0.0    0.0  ...       6      1         2\n",
            "       2.00           0.0         0.0    0.0  ...      15      9         2\n",
            "       3.00           0.0         0.0    0.0  ...       5      4         1\n",
            "       4.00           0.0         0.0    0.0  ...      13      4         5\n",
            "...                   ...         ...    ...  ...     ...    ...       ...\n",
            "male   70.00          0.0         2.0    1.0  ...       3      1         0\n",
            "       70.50          0.0         1.0    1.0  ...       3      0         0\n",
            "       71.00          0.0         2.0    2.0  ...       2      0         0\n",
            "       74.00          0.0         1.0    1.0  ...       3      0         0\n",
            "       80.00          0.0         1.0    1.0  ...       1      0         1\n",
            "\n",
            "[145 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANEO5Ci-zZru",
        "colab_type": "text"
      },
      "source": [
        "Q24. Write a Pandas program to create the Pivot table and find survival\n",
        "rate by gender?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw7mH5BszZrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "634e3973-c678-468a-98ac-4bc951e6b505"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('/content/drive/My Drive/Copy of titanic.csv')\n",
        "age = pd.cut(df['age'], [0, 20, 55])\n",
        "result = df.pivot_table('survived', index=['sex', age], columns='class')\n",
        "print(result)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class               First    Second     Third\n",
            "sex    age                                   \n",
            "female (0, 20]   0.928571  1.000000  0.510638\n",
            "       (20, 55]  0.968750  0.912281  0.407407\n",
            "male   (0, 20]   0.571429  0.526316  0.197368\n",
            "       (20, 55]  0.440000  0.054054  0.134503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yb6NUW_zZrz",
        "colab_type": "text"
      },
      "source": [
        "Q25. Write a pandas program to make partition each of the passengers\n",
        "into 4 categories based on their age.\n",
        " \n",
        "Note: Age categories- (0, 10), (10, 30), (30, 60), (60, 80)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7yDZHFNzZr1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "4105d256-cd03-45e7-f30b-1d5c62aa3e46"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('/content/drive/My Drive/Copy of titanic.csv')\n",
        "result = pd.cut(df['age'], [0, 10, 30, 60, 80])\n",
        "print(result)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0      (10.0, 30.0]\n",
            "1      (30.0, 60.0]\n",
            "2      (10.0, 30.0]\n",
            "3      (30.0, 60.0]\n",
            "4      (30.0, 60.0]\n",
            "           ...     \n",
            "886    (10.0, 30.0]\n",
            "887    (10.0, 30.0]\n",
            "888             NaN\n",
            "889    (10.0, 30.0]\n",
            "890    (30.0, 60.0]\n",
            "Name: age, Length: 891, dtype: category\n",
            "Categories (4, interval[int64]): [(0, 10] < (10, 30] < (30, 60] < (60, 80]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JzDD5wAzZr5",
        "colab_type": "text"
      },
      "source": [
        "Q26. Write a pandas program to create the Pivot table and find survival\n",
        "rate by the gender, age of the different categories of various\n",
        "classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvX4yuOIzZr6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "56436f5e-65ba-4896-ac5c-7f48b6decb7b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('/content/drive/My Drive/Copy of titanic.csv')\n",
        "age = pd.cut(df['age'], [0, 20, 55])\n",
        "result = df.pivot_table('survived', index=['sex', age], columns='class')\n",
        "print(result)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class               First    Second     Third\n",
            "sex    age                                   \n",
            "female (0, 20]   0.928571  1.000000  0.510638\n",
            "       (20, 55]  0.968750  0.912281  0.407407\n",
            "male   (0, 20]   0.571429  0.526316  0.197368\n",
            "       (20, 55]  0.440000  0.054054  0.134503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRvJvS_VzZr-",
        "colab_type": "text"
      },
      "source": [
        "Q27. Write a pandas program to create the Pivot table and calculate\n",
        "number of women and men were in a particular cabin class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ncflzuUzZr_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f668f4ad-770b-4547-9907-7bab26a3f0c9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('/content/drive/My Drive/Copy of titanic.csv')\n",
        "result = df.pivot_table(index=['sex'], columns=['pclass'], aggfunc='count')\n",
        "print(result)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Unnamed: 15       adult_male            ... survived            who          \n",
            "pclass           1  2  3          1    2    3  ...        1    2    3    1    2    3\n",
            "sex                                            ...                                  \n",
            "female           0  0  0         94   76  144  ...       94   76  144   94   76  144\n",
            "male             0  0  0        122  108  347  ...      122  108  347  122  108  347\n",
            "\n",
            "[2 rows x 42 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Jzp57izZsD",
        "colab_type": "text"
      },
      "source": [
        "Q28. Write a pandas program to create the Pivot table and separate\n",
        "the gender according to whether they travelled alone or not to get\n",
        "the probability of survival\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB-7obwKzZsE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9bce66af-daa5-455b-d624-9a832fde0629"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('/content/drive/My Drive/Copy of titanic.csv')\n",
        "result = df.pivot_table( 'survived' , [ 'sex' , 'alone' ] , 'class' )\n",
        "print(result)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class            First    Second     Third\n",
            "sex    alone                              \n",
            "female False  0.966667  0.931818  0.416667\n",
            "       True   0.970588  0.906250  0.616667\n",
            "male   False  0.425532  0.277778  0.180723\n",
            "       True   0.333333  0.097222  0.121212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Loe-T1-YzZsI",
        "colab_type": "text"
      },
      "source": [
        "Q29. Write a pandas program to create the Pivot table and find the\n",
        "probability of survival by class, gender, solo boarding, and the port\n",
        "of embarkation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZIoaUe8zZsJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "11bb0f09-b735-4e62-fedc-4095be13d4b9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('/content/drive/My Drive/Copy of titanic.csv')\n",
        "result = df.pivot_table('survived', ['sex' , 'alone' ], [ 'embark_town', 'class' ])\n",
        "print(result)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embark_town  Cherbourg                      ... Southampton                    \n",
            "class            First    Second     Third  ...       First    Second     Third\n",
            "sex    alone                                ...                                \n",
            "female False  1.000000  1.000000  0.611111  ...    0.941176  0.923077  0.327586\n",
            "       True   0.944444  1.000000  0.800000  ...    1.000000  0.892857  0.466667\n",
            "male   False  0.473684  0.166667  0.500000  ...    0.407407  0.300000  0.142857\n",
            "       True   0.347826  0.250000  0.151515  ...    0.326923  0.089552  0.123762\n",
            "\n",
            "[4 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r23wpiOBzZsN",
        "colab_type": "text"
      },
      "source": [
        "Q30. Write a pandas program to get current date, oldest date and\n",
        "number of days between Current date and the oldest date of Ufo\n",
        "dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvKh2DNQzZsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('ufo.csv')\n",
        "df['Date_time'] = df['Date_time'].astype('datetime64[ns]')\n",
        "print(\"Original Dataframe:\")\n",
        "print(df.head())\n",
        "print(\"\\nCurrent date of Ufo dataset:\")\n",
        "print(df.Date_time.max())\n",
        "print(\"\\nOldest date of Ufo dataset:\")\n",
        "print(df.Date_time.min())\n",
        "print(\"\\nNumber of days between Current date and oldest date of Ufo dataset:\")\n",
        "print((df.Date_time.max() - df.Date_time.min()).days)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4b3zLvEzZsU",
        "colab_type": "text"
      },
      "source": [
        "Q31. Write a pandas program to get all sighting days of the\n",
        "unidentified flying object (ufo) between 1950-10-10 and 1960-10-\n",
        "10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWjVVsU9zZsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(r'ufo.csv')\n",
        "df['Date_time'] = df['Date_time'].astype('datetime64[ns]')\n",
        "print(\"Original Dataframe:\")\n",
        "print(df.head())\n",
        "print(\"\\nSighting days of the unidentified flying object (ufo) between 1949-10-10 and 1960-10-10:\")\n",
        "selected_period = df[(df['Date_time'] >= '1950-01-01 00:00:00') & (df['Date_time'] <= '1960-12-31 23:59:59')]\n",
        "print(selected_period)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "486EvKnhzZsZ",
        "colab_type": "text"
      },
      "source": [
        "Q32. Write a Pandas program to extract the year, month, day, hour,\n",
        "minute, second, and weekday from unidentified flying object (UFO)\n",
        "reporting date."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjZFPaUMzZsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(r'ufo.csv')\n",
        "df['Date_time'] = df['Date_time'].astype('datetime64[ns]')\n",
        "print(\"Original Dataframe:\")\n",
        "print(df.head())\n",
        "print(\"\\nYear:\")\n",
        "print(df.Date_time.dt.year.head())\n",
        "print(\"\\nMonth:\")\n",
        "print(df.Date_time.dt.month.head())\n",
        "print(\"\\nDay:\")\n",
        "print(df.Date_time.dt.day.head())\n",
        "print(\"\\nHour:\")\n",
        "print(df.Date_time.dt.hour.head())\n",
        "print(\"\\nMinute:\")\n",
        "print(df.Date_time.dt.minute.head())\n",
        "print(\"\\nSecond:\")\n",
        "print(df.Date_time.dt.second.head())\n",
        "print(\"\\nWeekday:\")\n",
        "print(df.Date_time.dt.weekday_name.head())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXQpDDEUzZsd",
        "colab_type": "text"
      },
      "source": [
        "Q33. Write a pandas program to count year-country wise frequency of\n",
        "reporting dates of the unidentified flying object(UFO).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhwhuVGuzZsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(r'ufo.csv')\n",
        "df['Date_time'] = df['Date_time'].astype('datetime64[ns]')\n",
        "print(\"Original Dataframe:\")\n",
        "print(df.head())\n",
        "df['Year'] = df['Date_time'].apply(lambda x: \"%d\" % (x.year))\n",
        "result = df.groupby(['Year', 'country']).size()\n",
        "print(\"\\nCountry-year wise frequency of reporting dates of UFO:\")\n",
        "print(result)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9VkpYfWzZsh",
        "colab_type": "text"
      },
      "source": [
        "Q34. Write a pandas program to get the difference (in days) between\n",
        "documented date and reporting date of unidentified flying object\n",
        "(UFO)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOJfHc1ZzZsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(r'ufo.csv')\n",
        "df['Date_time'] = df['Date_time'].astype('datetime64[ns]')\n",
        "df['date_documented'] = df['date_documented'].astype('datetime64[ns]')\n",
        "print(\"Original Dataframe:\")\n",
        "print(df.head())\n",
        "print(\"\\nDifference (in days) between documented date and reporting date of UFO:\")\n",
        "df['Difference'] = (df['date_documented'] - df['Date_time']).dt.days\n",
        "print(df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS4RAKa5zZsm",
        "colab_type": "text"
      },
      "source": [
        "Q35. Write a pandas program to generate sequences of fixedfrequency dates and time spans."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLsOy6Ia5W-w",
        "colab_type": "text"
      },
      "source": [
        "#Source: https://bit.ly/2XDY2XN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h54xF1Z5zZsm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38095347-f9a6-4725-dd63-65ed4c970e75"
      },
      "source": [
        "import pandas as pd\n",
        "dtr = pd.date_range('2018-01-01', periods=12, freq='H')\n",
        "print(\"Hourly frequency:\")\n",
        "print(dtr)\n",
        "dtr = pd.date_range('2018-01-01', periods=12, freq='min')\n",
        "print(\"\\nMinutely frequency:\")\n",
        "print(dtr)\n",
        "dtr = pd.date_range('2018-01-01', periods=12, freq='S')\n",
        "print(\"\\nSecondly frequency:\")\n",
        "print(dtr)\n",
        "dtr = pd.date_range('2018-01-01', periods=12, freq='2H')\n",
        "print(\"nMultiple Hourly frequency:\")\n",
        "print(dtr)\n",
        "dtr = pd.date_range('2018-01-01', periods=12, freq='5min')\n",
        "print(\"\\nMultiple Minutely frequency:\")\n",
        "print(dtr)\n",
        "dtr = pd.date_range('2018-01-01', periods=12, freq='BQ')\n",
        "print(\"\\nMultiple Secondly frequency:\")\n",
        "print(dtr)\n",
        "dtr = pd.date_range('2018-01-01', periods=12, freq='w')\n",
        "print(\"\\nWeekly frequency:\")\n",
        "print(dtr)\n",
        "dtr = pd.date_range('2018-01-01', periods=12, freq='2h20min')\n",
        "print(\"\\nCombine together day and intraday offsets-1:\")\n",
        "print(dtr)\n",
        "dtr = pd.date_range('2018-01-01', periods=12, freq='1D10U')\n",
        "print(\"\\nCombine together day and intraday offsets-2:\")\n",
        "print(dtr)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hourly frequency:\n",
            "DatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 01:00:00',\n",
            "               '2018-01-01 02:00:00', '2018-01-01 03:00:00',\n",
            "               '2018-01-01 04:00:00', '2018-01-01 05:00:00',\n",
            "               '2018-01-01 06:00:00', '2018-01-01 07:00:00',\n",
            "               '2018-01-01 08:00:00', '2018-01-01 09:00:00',\n",
            "               '2018-01-01 10:00:00', '2018-01-01 11:00:00'],\n",
            "              dtype='datetime64[ns]', freq='H')\n",
            "\n",
            "Minutely frequency:\n",
            "DatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 00:01:00',\n",
            "               '2018-01-01 00:02:00', '2018-01-01 00:03:00',\n",
            "               '2018-01-01 00:04:00', '2018-01-01 00:05:00',\n",
            "               '2018-01-01 00:06:00', '2018-01-01 00:07:00',\n",
            "               '2018-01-01 00:08:00', '2018-01-01 00:09:00',\n",
            "               '2018-01-01 00:10:00', '2018-01-01 00:11:00'],\n",
            "              dtype='datetime64[ns]', freq='T')\n",
            "\n",
            "Secondly frequency:\n",
            "DatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 00:00:01',\n",
            "               '2018-01-01 00:00:02', '2018-01-01 00:00:03',\n",
            "               '2018-01-01 00:00:04', '2018-01-01 00:00:05',\n",
            "               '2018-01-01 00:00:06', '2018-01-01 00:00:07',\n",
            "               '2018-01-01 00:00:08', '2018-01-01 00:00:09',\n",
            "               '2018-01-01 00:00:10', '2018-01-01 00:00:11'],\n",
            "              dtype='datetime64[ns]', freq='S')\n",
            "nMultiple Hourly frequency:\n",
            "DatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 02:00:00',\n",
            "               '2018-01-01 04:00:00', '2018-01-01 06:00:00',\n",
            "               '2018-01-01 08:00:00', '2018-01-01 10:00:00',\n",
            "               '2018-01-01 12:00:00', '2018-01-01 14:00:00',\n",
            "               '2018-01-01 16:00:00', '2018-01-01 18:00:00',\n",
            "               '2018-01-01 20:00:00', '2018-01-01 22:00:00'],\n",
            "              dtype='datetime64[ns]', freq='2H')\n",
            "\n",
            "Multiple Minutely frequency:\n",
            "DatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 00:05:00',\n",
            "               '2018-01-01 00:10:00', '2018-01-01 00:15:00',\n",
            "               '2018-01-01 00:20:00', '2018-01-01 00:25:00',\n",
            "               '2018-01-01 00:30:00', '2018-01-01 00:35:00',\n",
            "               '2018-01-01 00:40:00', '2018-01-01 00:45:00',\n",
            "               '2018-01-01 00:50:00', '2018-01-01 00:55:00'],\n",
            "              dtype='datetime64[ns]', freq='5T')\n",
            "\n",
            "Multiple Secondly frequency:\n",
            "DatetimeIndex(['2018-03-30', '2018-06-29', '2018-09-28', '2018-12-31',\n",
            "               '2019-03-29', '2019-06-28', '2019-09-30', '2019-12-31',\n",
            "               '2020-03-31', '2020-06-30', '2020-09-30', '2020-12-31'],\n",
            "              dtype='datetime64[ns]', freq='BQ-DEC')\n",
            "\n",
            "Weekly frequency:\n",
            "DatetimeIndex(['2018-01-07', '2018-01-14', '2018-01-21', '2018-01-28',\n",
            "               '2018-02-04', '2018-02-11', '2018-02-18', '2018-02-25',\n",
            "               '2018-03-04', '2018-03-11', '2018-03-18', '2018-03-25'],\n",
            "              dtype='datetime64[ns]', freq='W-SUN')\n",
            "\n",
            "Combine together day and intraday offsets-1:\n",
            "DatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 02:20:00',\n",
            "               '2018-01-01 04:40:00', '2018-01-01 07:00:00',\n",
            "               '2018-01-01 09:20:00', '2018-01-01 11:40:00',\n",
            "               '2018-01-01 14:00:00', '2018-01-01 16:20:00',\n",
            "               '2018-01-01 18:40:00', '2018-01-01 21:00:00',\n",
            "               '2018-01-01 23:20:00', '2018-01-02 01:40:00'],\n",
            "              dtype='datetime64[ns]', freq='140T')\n",
            "\n",
            "Combine together day and intraday offsets-2:\n",
            "DatetimeIndex([       '2018-01-01 00:00:00', '2018-01-02 00:00:00.000010',\n",
            "               '2018-01-03 00:00:00.000020', '2018-01-04 00:00:00.000030',\n",
            "               '2018-01-05 00:00:00.000040', '2018-01-06 00:00:00.000050',\n",
            "               '2018-01-07 00:00:00.000060', '2018-01-08 00:00:00.000070',\n",
            "               '2018-01-09 00:00:00.000080', '2018-01-10 00:00:00.000090',\n",
            "               '2018-01-11 00:00:00.000100', '2018-01-12 00:00:00.000110'],\n",
            "              dtype='datetime64[ns]', freq='86400000010U')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qscHFSNIzZsr",
        "colab_type": "text"
      },
      "source": [
        "Q36. Write a pandas program to manipulate and convert date times\n",
        "with timezone information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvf5DLXdzZss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "60f2f272-9053-4501-9b30-b4fe6ba7e7c1"
      },
      "source": [
        "import pandas as pd\n",
        "dtt = pd.date_range('2018-01-01', periods=3, freq='H')\n",
        "dtt = dtt.tz_localize('UTC')\n",
        "print(dtt)\n",
        "print(\"\\nFrom UTC to America/Los_Angeles:\")\n",
        "dtt = dtt.tz_convert('America/Los_Angeles')\n",
        "print(dtt)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DatetimeIndex(['2018-01-01 00:00:00+00:00', '2018-01-01 01:00:00+00:00',\n",
            "               '2018-01-01 02:00:00+00:00'],\n",
            "              dtype='datetime64[ns, UTC]', freq='H')\n",
            "\n",
            "From UTC to America/Los_Angeles:\n",
            "DatetimeIndex(['2017-12-31 16:00:00-08:00', '2017-12-31 17:00:00-08:00',\n",
            "               '2017-12-31 18:00:00-08:00'],\n",
            "              dtype='datetime64[ns, America/Los_Angeles]', freq='H')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMActU2SzZsv",
        "colab_type": "text"
      },
      "source": [
        "Q37. Write a pandas program to create the graphical analysis of UFO\n",
        "(unidentified flying object) Sightings year."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnLoIAm6zZsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "df = pd.read_csv(r'ufo.csv')\n",
        "df['Date_time'] = df['Date_time'].astype('datetime64[ns]')\n",
        "df[\"ufo_yr\"] = df.Date_time.dt.year\n",
        "years_data = df.ufo_yr.value_counts()\n",
        "years_index = years_data.index  # x ticks\n",
        "years_values = years_data.get_values()\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.xticks(rotation = 60)\n",
        "plt.title('UFO Sightings by Year')\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of reports\")\n",
        "years_plot = sns.barplot(x=years_index[:60],y=years_values[:60], palette = \"Reds\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI20C0XYzZsz",
        "colab_type": "text"
      },
      "source": [
        "Q38. Write a pandas program to create a comparison of the top 10\n",
        "years in which the (UFO) was sighted VS each Month."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECdalhvAzZs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(r'ufo.csv')\n",
        "df['Date_time'] = df['Date_time'].astype('datetime64[ns]')\n",
        "most_sightings_years = df['Date_time'].dt.year.value_counts().head(10)\n",
        "def is_top_years(year):\n",
        "   if year in most_sightings_years.index:\n",
        "       return year\n",
        "hour_v_year = df.pivot_table(columns=df['Date_time'].dt.hour,index=df['Date_time'].dt.year.apply(is_top_years),aggfunc='count',values='city')\n",
        "hour_v_year.columns = hour_v_year.columns.astype(int)\n",
        "hour_v_year.columns = hour_v_year.columns.astype(str) + \":00\"\n",
        "hour_v_year.index = hour_v_year.index.astype(int)\n",
        "print(\"\\nComparison of the top 10 years in which the UFO was sighted vs the hours of the day:\")\n",
        "print(hour_v_year.head(10))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aohtc00IzZs3",
        "colab_type": "text"
      },
      "source": [
        "Q39. Write a pandas program to create a heatmap (rectangular data as\n",
        "a colour-encoded matrix) for comparison of top 10 years in\n",
        "which (UFO ) was sighted VS each Month."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG8lEuHUzZs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv(r'ufo.csv')\n",
        "df['Date_time'] = df['Date_time'].astype('datetime64[ns]')\n",
        "most_sightings_years = df['Date_time'].dt.year.value_counts().head(10)\n",
        "def is_top_years(year):\n",
        "   if year in most_sightings_years.index:\n",
        "       return year\n",
        "month_vs_year = df.pivot_table(columns=df['Date_time'].dt.month,index=df['Date_time'].dt.year.apply(is_top_years),aggfunc='count',values='city')\n",
        "month_vs_year.columns = month_vs_year.columns.astype(int)\n",
        "print(\"\\nHeatmap for comparison of the top 10 years in which the UFO was sighted vs each month:\")\n",
        "plt.figure(figsize=(10,8))\n",
        "ax = sns.heatmap(month_vs_year, vmin=0, vmax=4)\n",
        "ax.set_xlabel('Month').set_size(20)\n",
        "ax.set_ylabel('Year').set_size(20)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk-t_4GwzZs8",
        "colab_type": "text"
      },
      "source": [
        "Q40. Write a pandas program to create a Timewheel of Hour VS Year\n",
        "comparison of the top 10 years in which the (UFO) was sighted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4iBwQanzZs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "df = pd.read_csv(r'ufo.csv')\n",
        "df['Date_time'] = df['Date_time'].astype('datetime64[ns]')\n",
        "most_sightings_years = df['Date_time'].dt.year.value_counts().head(10)\n",
        "def is_top_years(year):\n",
        "   if year in most_sightings_years.index:\n",
        "       return year\n",
        "month_vs_year = df.pivot_table(columns=df['Date_time'].dt.month,index=df['Date_time'].dt.year.apply(is_top_years),aggfunc='count',values='city')\n",
        "month_vs_year.index = month_vs_year.index.astype(int)\n",
        "month_vs_year.columns = month_vs_year.columns.astype(int)\n",
        "print(\"\\nComparison of the top 10 years in which the UFO was sighted vs each month:\")\n",
        "def pie_heatmap(table, cmap='coolwarm_r', vmin=None, vmax=None,inner_r=0.25, pie_args={}):\n",
        "   n, m = table.shape\n",
        "   vmin= table.min().min() if vmin is None else vmin\n",
        "   vmax= table.max().max() if vmax is None else vmax\n",
        "\n",
        "   centre_circle = plt.Circle((0,0),inner_r,edgecolor='black',facecolor='white',fill=True,linewidth=0.25)\n",
        "   plt.gcf().gca().add_artist(centre_circle)\n",
        "   norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
        "   cmapper = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
        "\n",
        "   for i, (row_name, row) in enumerate(table.iterrows()):\n",
        "       labels = None if i > 0 else table.columns\n",
        "       wedges = plt.pie([1] * m,radius=inner_r+float(n-i)/n, colors=[cmapper.to_rgba(x) for x in row.values],\n",
        "           labels=labels, startangle=90, counterclock=False, wedgeprops={'linewidth':-1}, **pie_args)\n",
        "       plt.setp(wedges[0], edgecolor='grey',linewidth=1.5)\n",
        "       wedges = plt.pie([1], radius=inner_r+float(n-i-1)/n, colors=['w'], labels=[row_name], startangle=-90, wedgeprops={'linewidth':0})\n",
        "       plt.setp(wedges[0], edgecolor='grey',linewidth=1.5)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title(\"Timewheel of Hour Vs Year\",y=1.08,fontsize=30)\n",
        "pie_heatmap(month_vs_year, vmin=-20,vmax=80,inner_r=0.2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqnTi265zZtB",
        "colab_type": "text"
      },
      "source": [
        "## Great Job!"
      ]
    }
  ]
}